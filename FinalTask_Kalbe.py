# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xjRStMmYPEi7JP89gp13pae7OlV_NeMq
"""

#import library
import pandas as pd
from sklearn.cluster import KMeans
import statsmodels.api as sm
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf
from statsmodels.graphics.tsaplots import plot_pacf
import statsmodels.tsa.stattools as ts
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from statsmodels.tsa.seasonal import seasonal_decompose
import statsmodels.tsa.statespace.sarimax as sm
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn import preprocessing
from sklearn.metrics import silhouette_score

#import data
df_product = pd.read_csv("Case Study - Product.csv",sep=';', skipinitialspace=True)
df_customer = pd.read_csv("Case Study - Customer.csv",sep=';', skipinitialspace=True)
df_tranksaksi = pd.read_csv("Case Study - Transaction.csv",sep=';', skipinitialspace=True)
df_store  = pd.read_csv("Case Study - Store.csv",sep=';', skipinitialspace=True)

#melakukan pengecekan untuk missing value
mc = df_customer.isna().sum().sum()
mp = df_product.isna().sum().sum()
mt = df_tranksaksi.isna().sum().sum()
ms = df_store.isna().sum().sum()

# melakukan pengecekan data duplikat
d1 = df_customer.duplicated()
d2 = df_product.duplicated()
d3 = df_store.duplicated()
d4 = df_tranksaksi.duplicated()

print("TOTAL NILAI MISSING VALUE DISETIAP FILE "
      "\ndata customer = ",mc ,
      "\n data produk = ",mp ,
      "\n data transaksi = ",mt ,
      "\n data toko = ",ms)
print("\n")
print("TOTAL NILAI MISSING VALUE DISETIAP FILE"
      "\n data customer = ",d1,
      "\n data produk = ",d2 ,
      "\n data transaksi = ",d3,
      "\n data toko = ",d4)

#melakukan penghapusan missing value
df_customer = df_customer.dropna()
mc = df_customer.isna().sum().sum()

#mengubah data
df_customer['Income'] = df_customer['Income'].str.replace(',', '.').astype('float')
df_store['Latitude'] = df_store['Latitude'].str.replace(',', '.').astype('float')
df_store['Longitude'] = df_store['Longitude'].str.replace(',', '.').astype('float')
df_tranksaksi['Date'] = pd.to_datetime(df_tranksaksi['Date'], format="%d/%m/%Y")

#menggabungkan data
df_merge = pd.merge(df_store,df_tranksaksi, on="StoreID")
df_merge = pd.merge(df_merge,df_customer, on="CustomerID")
df_merge = pd.merge(df_merge,df_product.drop(columns='Price'), on="ProductID")

df_merge.info()

df_merge.describe()

df_merge.head()

# data Time Series
data_time = df_merge.groupby('Date')['Qty'].sum().reset_index()
data = data_time.set_index('Date')
# resample
data1 = data.resample('D').sum()

# Membagi data Train  80% dan data test 20%
train_size = int(len(data1) * 0.8)
train_data, test_data = data1[:train_size], data1[train_size:]
print(train_data.shape, test_data.shape)

#mevisualisasikan data test dan data train
plt.figure(figsize=(12,5))
sns.lineplot(data=train_data, x=train_data.index, y=train_data['Qty'], color= 'black')
sns.lineplot(data=test_data, x=test_data.index, y=test_data['Qty'], color= 'red')
plt.title('data train dan Test', fontsize=18)
plt.show()

#metode time series ARIMA (Autoregressive Integrated Moving Average)

#memisalkan
p = 0  # Order of Autoregression
d = 0  # Degree of Differencing
q = 0  # Order of Moving Average

#mencoba beberapa kombinasi order dan seasonal order, dan menemukan beberapa paramater yang sesuai dengan prediksi

#membuat model ARIMA dengan parameter
model = sm.SARIMAX(train_data, order=(p, d, q),seasonal_order=(1,1,0,7))

# Latih model
model_fit = model.fit()

#Menentukan indeks awal dan akhir data yang akan diprediksi
 start_idx = len(train_data)
end_idx = len(train_data) + len(test_data) - 1
predictions = model_fit.predict(start=start_idx, end=end_idx, dynamic=False)
print(predictions)

#memvisualisasikan plot prediksi
plt.figure(figsize=(12,5))
plt.plot(test_data, label='Qty')
plt.plot(predictions, color='red', label='Predicted')
plt.title('Prediksi', fontsize=18)
plt.legend()

# Evaluasi performa
mse = mean_squared_error(test_data, predictions)
print(f"Mean Squared Error: {mse}")

#melakukan pemodelan dengan clustering
# Menggabungkan data berdasarkan CustomerID
df_pre = df_merge.groupby('CustomerID').agg({
    'TransactionID': 'count',
    'Qty': 'sum',
    'TotalAmount': 'sum'
}).reset_index()

df_pre2 = df_pre.drop(columns="CustomerID")
df_pre2

#Standarisasi dataset
X = df_pre2.values
X_std = StandardScaler().fit_transform(X)
df_std = pd.DataFrame(data=X_std,columns=df_pre2.columns)
df_std.isna().sum()

df_std

#Normalisasi dataset dengan minmaxscaler
X_norm = MinMaxScaler().fit_transform(X)
print(X_norm)
# Normalisasi dataset dengan preprocessing sklearn
X_norm2 = preprocessing.normalize(df_pre2)
print(X_norm2)

#menentuka k cluster terbaik
wcss=[]
for n in range(1 , 11):
  model1 = KMeans(n_clusters=n, init='k-means++', n_init = 10, max_iter=100, tol =0.0001, random_state = 100)
  model1.fit(X_std)
  wcss.append(model1.inertia_)
print(wcss)

#gambar sebagai patokan untuk cluster kmeans terbaik
plt.figure(figsize=(8,3))
plt.plot(list(range(1, 11)), wcss, color='royalblue', marker='o', linewidth=2, markersize=12, markerfacecolor='m', markeredgecolor='m')
plt.xlabel('Jumlah Cluster', fontsize=15)
plt.ylabel('WCSS', fontsize=15)
plt.show()

#KMeans terbaik = 4
kmeans_4 =KMeans(n_clusters=4, init='k-means++', n_init=10, max_iter=100, tol=0.0001, random_state=100)
kmeans_4.fit(X_std)

# Masukan cluster ke dataset
df_pre2['cluster'] = kmeans_4.labels_
df_pre2.head()

#memahami cluster
df_pre2['CustomerID'] = df_pre['CustomerID']
df_clust_mean = df_pre2.groupby('cluster').agg({'CustomerID':'count','TransactionID':'mean','Qty':'mean','TotalAmount':'mean'})
df_clust_mean.sort_values('CustomerID', ascending= True)

#evaluasi perfoma clustering dengan silhouette coefficient
silhouette_coefficients = silhouette_score(X_std, kmeans_4.labels_)
print("inilah hasil evaluasi dari clustering =",silhouette_coefficients)